{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0015194f-f390-4b43-a01c-7aabba831282",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Chunk Articles with `unstructured`\n",
    "\n",
    "We will use [unstructured](https://unstructured.io/) for our primary chunking library. We are going to use this for the actual body content and it is common to change the arguments of the unstructured [partitioning](https://docs.unstructured.io/open-source/core-functionality/partitioning) functions upon future iterations where we are improving our Dataset curation for pre-training or fine-tuning or our chunking strategy for our VS index.\n",
    "\n",
    "**NOTE**: Since we are working with XML data we are going to use the [partition-xml](https://docs.unstructured.io/open-source/core-functionality/partitioning#partition-xml) function. There are many libraries out there that can make use of the xml tags we left in our body column and they can excluded easily with regex or opensource xml parsing library. Thus, we left the xml in the body to allow for discovery of new / different parsing strategies in the future.\n",
    "\n",
    "**NOTE**: YES. We could have used [partition-xml](https://docs.unstructured.io/open-source/core-functionality/partitioning#partition-xml) function to parse from file instead of from the `curated_articles` delta table. Similar to the above note, we did this to make future iterative improvements faster as reading text from file in blob storage has a much larger I/O preformance cost. This was a deliberate architecture decision for future enhancements, not just to conform to a [Medallion Architecture](https://www.databricks.com/glossary/medallion-architecture)... although we are doing that as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "48c061c8-89e2-4163-93a2-038f14770a71",
     "showTitle": true,
     "title": "Initialize biomed Configuration Class"
    }
   },
   "outputs": [],
   "source": [
    "%run ./config/setup_workflow $SHOW_TABLE=false $SHOW_GRAPHIC=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "618596f0-ebb5-431e-9da8-06a00ae1fcad",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# curated_articles_content will include all metadata fields we'll want in vectorsearches\n",
    "\n",
    "sql_path = biomed.processed_articles_content.sql_path\n",
    "with open(sql_path, 'r') as file:\n",
    "    sql = file.read()\n",
    "    print(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb3ba469-557f-4cbf-8fec-7160650edf15",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create a UDF that will chunk our article bodies\n",
    "from unstructured.partition.xml import partition_xml\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "import xml.etree.ElementTree as ET\n",
    "import html2text\n",
    "\n",
    "def chunk_xml_body(body: str, attrs: dict):\n",
    "    text_maker = html2text.HTML2Text()\n",
    "    root = ET.Element('root', attrib=attrs)\n",
    "    root.text = body\n",
    "    body_elements = partition_xml(text=str(ET.tostring(root, encoding='utf-8'), 'UTF-8'),\n",
    "                                  xml_keep_tags = False,\n",
    "                                  encoding='utf-8',\n",
    "                                  include_metadata=False,\n",
    "                                  languages=['eng',],\n",
    "                                  date_from_file_object=None,\n",
    "                                  chunking_strategy='by_title',\n",
    "                                  multipage_sections=True,\n",
    "                                  combine_text_under_n_chars=300,\n",
    "                                  new_after_n_chars=1400,\n",
    "                                  max_characters=1250)\n",
    "    body_chunks = [text_maker.handle(str(be.text)) for be in body_elements if len(be.text) >= 110]\n",
    "    return body_chunks\n",
    "\n",
    "chunk_xml_body_udf = udf(chunk_xml_body, ArrayType(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa2addae-0597-454c-822c-1a9515e490a2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(biomed.curated_articles_xml.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c7d01bd3-a131-4f13-aab1-788ee049a98d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get dataframe of new articles\n",
    "from pyspark.sql.functions import col, lit, concat\n",
    "from pyspark.sql.functions import xpath_string, explode, posexplode\n",
    "\n",
    "# Insert all previously unprocessed articles\n",
    "biomed.curated_articles_xml.df.alias(\"a\") \\\n",
    "      .join(biomed.processed_articles_content.df.select(col(\"pmid\")).distinct().alias(\"b\"),\n",
    "            col(\"a.AccessionID\") == col(\"b.pmid\"), \"left_anti\") \\\n",
    "      .withColumn('contents', chunk_xml_body_udf('body', 'attrs')) \\\n",
    "      .select(col('AccessionID').alias('pmid'),\n",
    "                  xpath_string(col('front'),lit('front/article-meta/title-group/article-title')).alias('title'),\n",
    "                  xpath_string(col('front'),lit('front/journal-meta/journal-title-group/journal-title')).alias('journal'),\n",
    "                  lit('NEED DESIRED CITATION FORMAT').alias('citation'),\n",
    "                  xpath_string(col('front'),lit('front/article-meta/pub-date/year')).alias('year'),\n",
    "                  posexplode('contents').alias('content_pos', 'content')) \\\n",
    "      .withColumn('id', concat(col('pmid'), lit('-'), col('content_pos'))) \\\n",
    "      .drop('content_pos') \\\n",
    "      .write.mode('append').saveAsTable(biomed.processed_articles_content.name)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3298070784032435,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "04_Chunk_Articles_Content",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
